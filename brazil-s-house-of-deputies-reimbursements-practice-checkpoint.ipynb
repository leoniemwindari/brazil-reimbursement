{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Import the needed library\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brazilian politicians are entitled to refunds if they spend any of their money on an activity that is enabling them to \"better serve the people\". The data of it are public but there are less analysis on it. There are a lot of very suspicious data regarding the deputies expending behavior. If we analyze the data, we could draw a conclusion and even find some insight, like : \n",
    "*  In which category does the the deputies spend more? \n",
    "*  Which political partys spend the most?\n",
    "*  Which state spend the most?\n",
    "*  In what year they spend the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this analysis is to detect a suspicious data, which we can know from finding the outliers. The purpose of this practice was to get myself into understanding outliers more, how to visualize it, how to detect it, and what ways can we do to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinda\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (10,12,14,15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Import the dataset\n",
    "deput_dataset = pd.read_csv('.ipynb_checkpoints/deputies_dataset.csv',)\n",
    "dir_dataset = pd.read_csv('.ipynb_checkpoints/dirty_deputies_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I make a copy of the data so the real data won't change and if I make mistake when analyzing the data, the real data won't get affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the original dataset\n",
    "#incase something is wrong\n",
    "#We will process the data using the copy of the data\n",
    "deputies_dataset = deput_dataset.copy()\n",
    "dirty_dataset = dir_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bugged_date</th>\n",
       "      <th>receipt_date</th>\n",
       "      <th>deputy_id</th>\n",
       "      <th>political_party</th>\n",
       "      <th>state_code</th>\n",
       "      <th>deputy_name</th>\n",
       "      <th>receipt_social_security_number</th>\n",
       "      <th>receipt_description</th>\n",
       "      <th>establishment_name</th>\n",
       "      <th>receipt_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-27 00:00:00</td>\n",
       "      <td>1772</td>\n",
       "      <td>PSB</td>\n",
       "      <td>SP</td>\n",
       "      <td>Abelardo Camarinha</td>\n",
       "      <td>3.530749e+12</td>\n",
       "      <td>Fuels and lubricants.</td>\n",
       "      <td>AUTO POSTO 314 NORTE LTDA</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-07-24 00:00:00</td>\n",
       "      <td>1772</td>\n",
       "      <td>PSB</td>\n",
       "      <td>SP</td>\n",
       "      <td>Abelardo Camarinha</td>\n",
       "      <td>8.202116e+12</td>\n",
       "      <td>Fuels and lubricants.</td>\n",
       "      <td>AUTO POSTO AEROPORTO  LTDA</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-02-17 00:00:00</td>\n",
       "      <td>1772</td>\n",
       "      <td>PSB</td>\n",
       "      <td>SP</td>\n",
       "      <td>Abelardo Camarinha</td>\n",
       "      <td>8.202116e+12</td>\n",
       "      <td>Fuels and lubricants.</td>\n",
       "      <td>AUTO POSTO AEROPORTO LTDA</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-15 00:00:00</td>\n",
       "      <td>1772</td>\n",
       "      <td>PSB</td>\n",
       "      <td>SP</td>\n",
       "      <td>Abelardo Camarinha</td>\n",
       "      <td>8.202116e+12</td>\n",
       "      <td>Fuels and lubricants.</td>\n",
       "      <td>AUTO POSTO AEROPORTO LTDA</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-27 00:00:00</td>\n",
       "      <td>1772</td>\n",
       "      <td>PSB</td>\n",
       "      <td>SP</td>\n",
       "      <td>Abelardo Camarinha</td>\n",
       "      <td>8.202116e+12</td>\n",
       "      <td>Fuels and lubricants.</td>\n",
       "      <td>AUTO POSTO AEROPORTO LTDA</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bugged_date         receipt_date  deputy_id political_party state_code  \\\n",
       "0            0  2013-03-27 00:00:00       1772             PSB         SP   \n",
       "1            0  2013-07-24 00:00:00       1772             PSB         SP   \n",
       "2            0  2013-02-17 00:00:00       1772             PSB         SP   \n",
       "3            0  2013-03-15 00:00:00       1772             PSB         SP   \n",
       "4            0  2013-01-27 00:00:00       1772             PSB         SP   \n",
       "\n",
       "          deputy_name  receipt_social_security_number    receipt_description  \\\n",
       "0  Abelardo Camarinha                    3.530749e+12  Fuels and lubricants.   \n",
       "1  Abelardo Camarinha                    8.202116e+12  Fuels and lubricants.   \n",
       "2  Abelardo Camarinha                    8.202116e+12  Fuels and lubricants.   \n",
       "3  Abelardo Camarinha                    8.202116e+12  Fuels and lubricants.   \n",
       "4  Abelardo Camarinha                    8.202116e+12  Fuels and lubricants.   \n",
       "\n",
       "           establishment_name  receipt_value  \n",
       "0   AUTO POSTO 314 NORTE LTDA             70  \n",
       "1  AUTO POSTO AEROPORTO  LTDA            104  \n",
       "2   AUTO POSTO AEROPORTO LTDA            100  \n",
       "3   AUTO POSTO AEROPORTO LTDA            100  \n",
       "4   AUTO POSTO AEROPORTO LTDA             77  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Catch a glimpse at the data\n",
    "deputies_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3014902, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find out the shape of the data\n",
    "deputies_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note :\n",
    "1. bugged_date: (binary) identify wether date had issues \n",
    "\n",
    "2. receiptdate: (datetime) receipt date // (int year) for when buggeddate == 1\n",
    "I think we could also drop this except for when the buggeddate == 1 but we will see\n",
    "\n",
    "3. Deputy id:id number. (didnt check if it changed across year/legislation period for deputies)\n",
    "I think there's no need for this feature because we already have the deputy_name\n",
    "\n",
    "4. politicalparty: (string) deputy political party\n",
    "We can join the data with the deputy dataset based on this feature\n",
    "\n",
    "5. statecode: (string) Brazil's state that elected the deputy \n",
    "\n",
    "6. deputyname: (string)\n",
    "\n",
    "7. receiptsocialsecuritynumber: might be a persons SS number (11 digits long) or a business id number (14 digits long). Many cases with issues. A social security number is used to identify employees for tax purposes and eventually is required for receipt of social security retirement money. Your social security number is also used by some other government services and by banks and credit issuers as a form of identification. It is unique where the number is used to identify each person. \n",
    "\n",
    "8. receiptdescription: (str / classes) class of spending under which the receipt fits\n",
    "\n",
    "9. establishmentname: (string) \n",
    "\n",
    "10. receiptvalue: (int) $BR, 3BR$ ~ 1USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we will :\n",
    "1. **See the relationship between dependent and independent variable** \n",
    "Decide whether to drop it or not (if it doesn't have a relationship with the dependent variable, drop it)\n",
    "Also drop the variable that doesn't help us to answer the questions we asked beforehand\n",
    "2. **Analyze the missing data**\n",
    "3. **Analyze the outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deputies_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will drop a couple of feature that I think is not important. In feature where you don't know you should drop it or not, you could plot the feature to know wheter the feature have a relationship with the dependet feature or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bugged_date', 'receipt_date', 'deputy_id', 'political_party',\n",
       "       'state_code', 'deputy_name', 'receipt_social_security_number',\n",
       "       'receipt_description', 'establishment_name', 'receipt_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deputies_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the feature that have no relationship with the dependent variable/ helps us answer the questions\n",
    "deputies_dataset = deputies_dataset.drop(['bugged_date', 'deputy_id', 'receipt_social_security_number', 'establishment_name'], axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "receipt_date           0.0\n",
       "political_party        0.0\n",
       "state_code             0.0\n",
       "deputy_name            0.0\n",
       "receipt_description    0.0\n",
       "receipt_value          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find out whether the data have missing value or not\n",
    "deputies_dataset.isnull().sum()/deputies_dataset.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we don't have any missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the feature 'receipt_date' is a datetime but in here the data type is still a string. So I will convert it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2013-03-27 00:00:00\n",
       "1    2013-07-24 00:00:00\n",
       "2    2013-02-17 00:00:00\n",
       "3    2013-03-15 00:00:00\n",
       "4    2013-01-27 00:00:00\n",
       "Name: receipt_date, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at the datetime format\n",
    "deputies_dataset['receipt_date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that not all of the data have the same format so I will check it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if all the data have the same format\n",
    "data_date = []\n",
    "for i in range(len(deputies_dataset)):\n",
    "    if len(deputies_dataset['receipt_date'][i])<5:\n",
    "        data_date.append(deputies_dataset['receipt_date'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013', '2013', '2013', '2013', '2013']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_date[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that in the receipt_date columns, some of it only consist of the year. Let's make sure it only consist the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the unique value from a list\n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "    # print list \n",
    "    for x in unique_list: \n",
    "        print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2011\n",
      "2015\n",
      "2012\n",
      "2017\n",
      "2010\n",
      "2016\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "unique(data_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was about to change the datatype into datetime but as I think again I think I rather keep it as string and I will take the year and put it into another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the year from the receipt_date\n",
    "year = []\n",
    "for i in range(len(deputies_dataset)):\n",
    "    if len(deputies_dataset['receipt_date'][i])>5:\n",
    "        year.append(((deputies_dataset['receipt_date'])[i].split()[0]).split('-')[0])\n",
    "    else:\n",
    "        year.append((deputies_dataset['receipt_date'])[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placing the value into new column in the dataset\n",
    "deputies_dataset['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deputies_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deputies_dataset['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirty_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will analyze the other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the glimpse of the dat\n",
    "dirty_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* u'deputyname': deputy official name\n",
    "* u'deputystate': state from which deputy was elected\n",
    "* u'politicalparty': deputy affiliation party\n",
    "* u'refunddescription': reason for refund\n",
    "* u'companyname': company utilized for expenses\n",
    "* u'companyid': company legal id (like a social security number for companies)\n",
    "* u'refunddate': unclear whether its the refund request or granted date\n",
    "* u'refundvalue' : value in R$ of refund ( 3R$ ~ 1USD )\n",
    "* u'partypg' : equivalent to US party (in Portuguese)\n",
    "* u'partyen': equivalent to US party (in English)\n",
    "* u'partytse': political party id number (used for voting)\n",
    "* u'partyregdate': political party creation date\n",
    "* u'partynmembers' : number of members in party\n",
    "* u'partyideology1': ideology1 of party\n",
    "* u'partyideology2' ideology2 of party, if applicable\n",
    "* u'partyideology3' ideology3 of party, if applicable\n",
    "* u'partyideology4' ideology4 of party, if applicable\n",
    "* u'partyposition': party official political position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will drop the feature that I think won't have a relationship with the dependent variable. We could also visualize the relationship between them to know if the feature have a relationship with the dependent variable or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop feature that have no relationship with the dependent variabel/ won't help us answer the questions\n",
    "dirty_dataset = dirty_dataset.drop([ 'party_pg',\n",
    "       'party_en', 'party_tse', 'party_ideology1', 'party_ideology2', 'party_ideology3',\n",
    "       'party_ideology4', 'party_position'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some missing value. I will delete the company id because we can know the company from the company_name. I will also drop deputy_state and political_party because I think there is no connection. For the refund_date I will extract the year and for the missing value, i assume that the data is in order so I will take the year after as a replacement for the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset = dirty_dataset.drop(['company_id','deputy_state','political_party'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for i in range(len(dirty_dataset)):\n",
    "    if len(str(dirty_dataset['refund_date'][i]))<10:\n",
    "        test.append(dirty_dataset['refund_date'][i])\n",
    "unique(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like in the refund_date we don't have the value of only the year like receipt_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the refund_date have various value format :\n",
    "1. 2016-07-29T00:00:00\n",
    "2. 1378520 \n",
    "3. nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nan(x):\n",
    "    return (x != x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['refund_date'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \"\" \n",
    "    \n",
    "    # return string   \n",
    "    return (str1.join(s)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(word): \n",
    "    return [char for char in word]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year1 = []\n",
    "for i in range(len(dirty_dataset)):\n",
    "    if len(str(dirty_dataset['refund_date'][i]))>8:\n",
    "        year1.append(((dirty_dataset['refund_date'])[i].split('T')[0]).split('-')[0])\n",
    "    elif is_nan(dirty_dataset['refund_date'][i]):\n",
    "        j=i+1\n",
    "        if is_nan(dirty_dataset['refund_date'][j]):\n",
    "            while is_nan(dirty_dataset['refund_date'][j]):\n",
    "                j+=1\n",
    "        year1.append(((dirty_dataset['refund_date'])[j].split('T')[0]).split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['year']=year1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think the party_regdate have to do with the analysis so I will just drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset = dirty_dataset.drop('party_regdate',axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The refund_date has some missing value but it's okay because we are going to use 'year'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deputies_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will divide it into the dependent and independent variable. Because we want to analyze the spending, the dependent variable would be receipt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var_deput = 'receipt_value'\n",
    "indep_var_deput = [i for i in deputies_dataset.columns if i!=dep_var_deput]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the outliers now but I will categorize the feature based on the type first, categorical or numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_var_deput = [i for i in indep_var_deput if (deputies_dataset[i].dtypes)=='O']\n",
    "num_var_deput = [i for i in indep_var_deput if i not in categ_var_deput]\n",
    "print('Categorical Feature:',categ_var_deput)\n",
    "print('Numerical Feature:',num_var_deput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'receipt_date' and 'year' suppose to be a datetime type so I will categorize it, and we don't have the numerical feature here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_var_deput = [i for i in categ_var_deput if 'date' in i or 'year' in i]\n",
    "categ_var_deput = [i for i in categ_var_deput  if i not in datetime_var_deput]\n",
    "print('Categorical Feature:',categ_var_deput)\n",
    "print('Datetime Feature:',datetime_var_deput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it! Now we can move to visualize the outliers. I will be using boxplot to visualize the categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categ_var_deput :\n",
    "    sns.boxplot(x=dep_var_deput, y = i, data=deputies_dataset)\n",
    "    plt.xlabel(dep_var_deput)\n",
    "    plt.ylabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categ_var_deput :\n",
    "    plt.bar(deputies_dataset[dep_var_deput], deputies_dataset[i],width=0.1)\n",
    "    plt.xlabel(dep_var_deput)\n",
    "    plt.ylabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have tons of outliers. Outliers were shown by the dots. The deputy_name have too many value as a categorical features but we can see later on which deputy have the biggest outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the value in the axis sorted, I will change the year datatype to int first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deputies_dataset['year'] = deputies_dataset['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deputies_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(deputies_dataset['receipt_value'],deputies_dataset['year'])\n",
    "plt.xlabel(dep_var_deput)\n",
    "plt.ylabel('year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that in some years, the receipt value is bigger than the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirty Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I will do the same for the dirty dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that a couple of feature that supposed to be an int, is an object type in this dataset. So I will change the datatype first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I found out that the party_nmembers have some 'nan' value so I will deal with it first. I think it has to do with the political party (which I already drop) but I will bring it back from the originial data. **NOTE : This is why you should always make a copy of your original data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['political_party']= dir_dataset['political_party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['political_party'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing=[dirty_dataset['political_party'][0]]\n",
    "party=dirty_dataset['political_party'][0]\n",
    "for i in range(1,len(dirty_dataset)):\n",
    "    if is_nan(dirty_dataset['political_party'][i]):\n",
    "        testing.append(party)\n",
    "    else:\n",
    "        testing.append(dirty_dataset['political_party'][i])\n",
    "        if dirty_dataset['political_party'][i]!= party:\n",
    "            party=dirty_dataset['political_party'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['political_party'] = testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['political_party'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am making a dictionary where it's contain the political party and the party_nmembers. I will change the nan value in party_nmembers with the value in the dictionary based on the political_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_member = {}\n",
    "for a in dirty_dataset['political_party'].unique():\n",
    "    for i in range(len(dirty_dataset)):\n",
    "        if dirty_dataset['political_party'][i]==a:\n",
    "            party_member[a]=dirty_dataset['party_nmembers'][i]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dirty_dataset['party_nmembers'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dirty_dataset['political_party'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the political_party have less value than the party_nmembers so there should be a value where it doesn't have the value or political_party. For this value I will use the median of the party_nmembers to replace the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining median\n",
    "abc = np.array(list((party_member.values()))).astype(int)\n",
    "abc = sorted(abc)\n",
    "length = int(len(abc)/2)\n",
    "med = (abc[int(length)]+abc[int(length+1)])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for return the value from dictionary keys\n",
    "def search_value(a,party_member,median):\n",
    "    for i in range(len(party_member)):\n",
    "        if a==list(party_member.keys())[0]:\n",
    "            return(list(party_member.values())[i])\n",
    "    return(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['party_nmembers']=dir_dataset['party_nmembers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['party_nmembers'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the missing value with the value from party_member dictionary\n",
    "number_member=[]\n",
    "for i in range(len(dirty_dataset)):\n",
    "    if dirty_dataset['party_nmembers'][i]=='Nan':\n",
    "        number_member.append(search_value(dirty_dataset['political_party'][i],party_member,med))\n",
    "    else :\n",
    "        number_member.append(dirty_dataset['party_nmembers'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the dataset with the value where the\n",
    "dirty_dataset['party_nmembers'] = number_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['party_nmembers'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now we don't have any 'Nan' value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset['party_nmembers'] = dirty_dataset['party_nmembers'].astype(int)\n",
    "dirty_dataset['year'] = dirty_dataset['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to deal with the outliers? Because in this project we are going to analyze the outliers, so we will make a new dataframe with only outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataset = dirty_dataset.drop('refund_date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var_dirty = 'refund_value'\n",
    "indep_var_dirty = [i for i in dirty_dataset.columns if i!=dep_var_dirty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_var_dirty = [i for i in indep_var_dirty if (dirty_dataset[i].dtypes)=='O']\n",
    "num_var_dirty = [i for i in indep_var_dirty if i not in categ_var_dirty]\n",
    "print('Categorical Feature:',categ_var_dirty)\n",
    "print('Numerical Feature:',num_var_dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categ_var_dirty:\n",
    "    sns.boxplot(x=dirty_dataset[dep_var_dirty], y=dirty_dataset[i])\n",
    "    plt.xlabel(dep_var_dirty)\n",
    "    plt.ylabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
